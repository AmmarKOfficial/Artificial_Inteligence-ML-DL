{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression Model For Breast Cancer .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Model For Breast *Cancer* "
      ],
      "metadata": {
        "id": "xlZenOal4o4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "hVsX2Yru4-DP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "import numpy as np           \t    #For working with arrays \n",
        "import matplotlib.pyplot as plt   #For plotting graphs\n",
        "import pandas as pd        \t      #For working withs datasets in datafram formate\n",
        "\n",
        "# Importing the dataset \n",
        "dataset = pd.read_csv('breast_cancer.csv')     #Importing the data.csv file\n",
        "X = dataset.iloc[:, :-1].values                # Independent veriables all rows and all columns expect last cloumn is in X\n",
        "Y = dataset.iloc[:, -1].values                 # Dependent veriable only last column and all rows\n",
        "\n",
        "# Missing Data Handleing \n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer.fit(X[:, 1:-1])\n",
        "X[:, 1:-1] = imputer.transform(X[:, 1:-1])\n",
        "\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split   # Import skleran library\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0) # Create Test and Train set that will be 20% Test and 80% training with random selection enable\n",
        "\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "SfNGbuDh5C3U"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Machine Learning Model"
      ],
      "metadata": {
        "id": "zztI1AH_9Q-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing The Respective Model And Traing With The Training Set \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state =0)\n",
        "classifier.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_HzFa6U9WSP",
        "outputId": "1703c098-02d5-4d53-c8fb-81ed615eb54d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting The Test Values"
      ],
      "metadata": {
        "id": "aJWEBzPX92Ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = classifier.predict(X_test)\n",
        "\n",
        "#Printing Predicted And Real Test Results Side By Side\n",
        "np.set_printoptions()\n",
        "print(np.concatenate((Y_pred.reshape(len(Y_pred),1), Y_test.reshape(len(Y_test),1)), 1))\n"
      ],
      "metadata": {
        "id": "fcj5UR4598kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Result Metrix"
      ],
      "metadata": {
        "id": "d9nduCl--Ocl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing The Confusion Metrix To Analyze The results\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(Y_test, Y_pred)\n",
        "print(cm)\n",
        "acc = accuracy_score(Y_test, Y_pred)\n",
        "print(f'Accuracy For Test Set  = {acc*100}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_IO7Eev-Tfj",
        "outputId": "a4612448-f955-4fe8-b63c-da821f5e8ed6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[103   4]\n",
            " [  5  59]]\n",
            "Accuracy For Test Set  = 94.73684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing The Accuracy"
      ],
      "metadata": {
        "id": "WU1SuB74-w8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy With K-Fold Cross Validation\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "Accuracies = cross_val_score(estimator = classifier, X = X_train, y = Y_train, cv = 10)\n",
        "Acc = Accuracies.mean()*100\n",
        "Std = Accuracies.std()*100\n",
        "\n",
        "print(f' Accuracy : {round(Acc, 2)}')\n",
        "print(f' Standard Deviation : {round(Std, 2)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUTJTTma-4X2",
        "outputId": "071714fb-6058-465b-ee9a-86d1fb7193c8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy : 96.87\n",
            " Standard Deviation : 1.57\n"
          ]
        }
      ]
    }
  ]
}